{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0757f563b7a403f9aaa3a1933aa19bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64ad34cf91824e48a0723bf7970f2313",
              "IPY_MODEL_84794c351aac451595fec64edf8333e7",
              "IPY_MODEL_bf6abc19cfb9488e897c146d83c8e527"
            ],
            "layout": "IPY_MODEL_21058c60244d411d8713e91dc9ed8bb6"
          }
        },
        "64ad34cf91824e48a0723bf7970f2313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5fcbb922fc04fb591aa92f7753a3033",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6b0b001cc5dc42e4b6b751d09a7e24d9",
            "value": "Generatingâ€‡testâ€‡split:â€‡"
          }
        },
        "84794c351aac451595fec64edf8333e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c67b7dcaef42ae83a5e4dd79045ded",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22fb57aa2d594fb580eb9975664aadb9",
            "value": 1
          }
        },
        "bf6abc19cfb9488e897c146d83c8e527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382b236b58884eb4bac230956b513679",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f77a3d277e4241f198f7283d303237fa",
            "value": "â€‡1521/0â€‡[00:01&lt;00:00,â€‡1190.93â€‡examples/s]"
          }
        },
        "21058c60244d411d8713e91dc9ed8bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5fcbb922fc04fb591aa92f7753a3033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0b001cc5dc42e4b6b751d09a7e24d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c67b7dcaef42ae83a5e4dd79045ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "22fb57aa2d594fb580eb9975664aadb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "382b236b58884eb4bac230956b513679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77a3d277e4241f198f7283d303237fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78ae67dc964b45168ae1a287ee226409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e5de9950ef749aba4e28b3d5720b443",
              "IPY_MODEL_9e4c6cdbc5144d9980ebbff828186997",
              "IPY_MODEL_1d2720f393d148afa88f0df2a6e92209"
            ],
            "layout": "IPY_MODEL_6255aae9d0d642378e268d165ffbe8b4"
          }
        },
        "3e5de9950ef749aba4e28b3d5720b443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c82f2fe4e04827905188cca3746b70",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_da58845283ce4ff2a665a3760510105f",
            "value": "Map:â€‡100%"
          }
        },
        "9e4c6cdbc5144d9980ebbff828186997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc2279dae034935852a32981ba831ca",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_381fd02a110f46bcbd55241a671a39d7",
            "value": 10
          }
        },
        "1d2720f393d148afa88f0df2a6e92209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b27f25b8ab5c45639410a5be0ef0a0f9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5c4563902af4a23b43693879d6f3017",
            "value": "â€‡10/10â€‡[00:00&lt;00:00,â€‡119.96â€‡examples/s]"
          }
        },
        "6255aae9d0d642378e268d165ffbe8b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c82f2fe4e04827905188cca3746b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da58845283ce4ff2a665a3760510105f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acc2279dae034935852a32981ba831ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "381fd02a110f46bcbd55241a671a39d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b27f25b8ab5c45639410a5be0ef0a0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c4563902af4a23b43693879d6f3017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import libs"
      ],
      "metadata": {
        "id": "yp6KMqYL_LBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ],
      "metadata": {
        "id": "RQRC97HcyHnc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95be7d5b",
        "outputId": "b97a85a3-e2dc-4c7e-e6ff-2b72c12ef33d"
      },
      "source": [
        "!pip install --quiet vllm scikit-learn tqdm\n",
        "print(\"Required libraries unsloth, vllm, scikit-learn, and tqdm installed successfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m474.9/474.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m355.0/355.0 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.4/72.4 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m285.4/285.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.6/821.6 kB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth-zoo 2026.1.3 requires tyro, which is not installed.\n",
            "unsloth 2026.1.3 requires tyro, which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "unsloth-zoo 2026.1.3 requires torchao>=0.13.0, but you have torchao 0.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequired libraries unsloth, vllm, scikit-learn, and tqdm installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to drive for test dataset"
      ],
      "metadata": {
        "id": "dj7X1r7Y_Qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROgYyP62M3SW",
        "outputId": "ce6040d7-1cd0-4ca0-8bfc-d37caf0378fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and tokenizer"
      ],
      "metadata": {
        "id": "M47uCXWI_aen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = \"drive/MyDrive/mipd_test.jsonl\"\n",
        "MAX_NEW_TOKENS = 256\n",
        "max_seq_length = 16384\n",
        "base_model_dir = \"drive/MyDrive/bielik-4.5b-base\"\n",
        "TEST_ROWS = None # None for whole dataset"
      ],
      "metadata": {
        "id": "0_f3y0eLsiz5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from google.colab import userdata\n",
        "import torch\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = base_model_dir,\n",
        "    max_seq_length = max_seq_length, # Choose any for long context!\n",
        "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
        "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        ")"
      ],
      "metadata": {
        "id": "FtPlFInruX_p",
        "outputId": "3e1d939a-7ae9-442e-ac7a-8669ff85aaa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2026.1.3: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.13.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and prepare dataset"
      ],
      "metadata": {
        "id": "N5OMhg3y_iaW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "f0757f563b7a403f9aaa3a1933aa19bb",
            "64ad34cf91824e48a0723bf7970f2313",
            "84794c351aac451595fec64edf8333e7",
            "bf6abc19cfb9488e897c146d83c8e527",
            "21058c60244d411d8713e91dc9ed8bb6",
            "e5fcbb922fc04fb591aa92f7753a3033",
            "6b0b001cc5dc42e4b6b751d09a7e24d9",
            "16c67b7dcaef42ae83a5e4dd79045ded",
            "22fb57aa2d594fb580eb9975664aadb9",
            "382b236b58884eb4bac230956b513679",
            "f77a3d277e4241f198f7283d303237fa",
            "78ae67dc964b45168ae1a287ee226409",
            "3e5de9950ef749aba4e28b3d5720b443",
            "9e4c6cdbc5144d9980ebbff828186997",
            "1d2720f393d148afa88f0df2a6e92209",
            "6255aae9d0d642378e268d165ffbe8b4",
            "45c82f2fe4e04827905188cca3746b70",
            "da58845283ce4ff2a665a3760510105f",
            "acc2279dae034935852a32981ba831ca",
            "381fd02a110f46bcbd55241a671a39d7",
            "b27f25b8ab5c45639410a5be0ef0a0f9",
            "c5c4563902af4a23b43693879d6f3017"
          ]
        },
        "id": "014141ff",
        "outputId": "ed0a29cc-1f3a-48a9-911d-655fc25891fe"
      },
      "source": [
        "import json\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 1. Load the test dataset\n",
        "dataset_test = load_dataset(\"json\", data_files={'test': test_data_path})\n",
        "\n",
        "# 3. Define a function named format_prompt\n",
        "def format_prompt(example):\n",
        "    # Combine instruction for system message and input for the user message\n",
        "    system_instruction = example['instruction']\n",
        "    user_message = example['input']\n",
        "\n",
        "    # Construct the ChatML formatted prompt\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_instruction},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "    example['prompt'] = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    # 5. Parse the output field into a Python list of strings (ground truth tags)\n",
        "    try:\n",
        "        # CLEANING STEP: Remove Markdown formatting\n",
        "        clean_json = example['output'].replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "        example['tags'] = json.loads(clean_json)['discovered_techniques']\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle cases where output might not be perfectly valid JSON (e.g., during training data prep)\n",
        "        example['tags'] = [] # Assign empty list if parsing fails\n",
        "        print(f\"Warning: Could not parse output: {example['output']}\")\n",
        "\n",
        "    # 6. Return the modified example\n",
        "    return example\n",
        "\n",
        "\n",
        "if(TEST_ROWS):\n",
        "  small_test_dataset = dataset_test['test'].select(range(TEST_ROWS))\n",
        "else:\n",
        "  small_test_dataset = dataset_test['test']\n",
        "# 7. Apply the format_prompt function to the loaded test dataset\n",
        "original_columns = small_test_dataset.column_names\n",
        "dataset_test_formatted = small_test_dataset.map(format_prompt, remove_columns=original_columns)\n",
        "\n",
        "print(\"Formatted prompts and ground truth tags generated for the test dataset.\")\n",
        "print(dataset_test_formatted)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0757f563b7a403f9aaa3a1933aa19bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78ae67dc964b45168ae1a287ee226409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted prompts and ground truth tags generated for the test dataset.\n",
            "Dataset({\n",
            "    features: ['prompt', 'tags'],\n",
            "    num_rows: 10\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define evaluation function\n",
        "Metric 1: Parsing Success Rate (Did it output valid JSON?).\n",
        "\n",
        "Metric 2: Format Correction Rate (How many invalid jsons were recovered?)\n",
        "\n",
        "Metric 3: Classification Performance (If parsable, how accurate?).\n"
      ],
      "metadata": {
        "id": "5NAGs3A6AJ9C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c58a713"
      },
      "source": [
        "import json\n",
        "import re\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_response(response_text: str, ground_truth_tags: list):\n",
        "    \"\"\"\n",
        "    Evaluates response with support for Dict format {\"discovered_techniques\": []}\n",
        "    and Markdown stripping.\n",
        "    \"\"\"\n",
        "    parsed_tags = []\n",
        "    parsing_status = 'Failed'\n",
        "\n",
        "    # 0. Pre-processing: Strip Markdown (Crucial for Strict Success)\n",
        "    # If we don't do this, valid JSON wrapped in ```json will fail strict parsing\n",
        "    clean_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "    # Attempt 1: Strict JSON parsing\n",
        "    try:\n",
        "        parsed_output = json.loads(clean_text)\n",
        "\n",
        "        # CASE A: Output is the expected Dictionary\n",
        "        if isinstance(parsed_output, dict):\n",
        "            # Extract the specific key we trained on\n",
        "            parsed_tags = parsed_output.get(\"discovered_techniques\", [])\n",
        "            # Check if the inner content is actually a list\n",
        "            if not isinstance(parsed_tags, list):\n",
        "                 # Try to force it if it's a string representation\n",
        "                 parsed_tags = []\n",
        "            parsing_status = 'Strict Success'\n",
        "\n",
        "        # CASE B: Model outputted a raw List (unlikely but possible)\n",
        "        elif isinstance(parsed_output, list):\n",
        "            parsed_tags = parsed_output\n",
        "            parsing_status = 'Strict Success'\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Parsed output is not a Dict or List.\")\n",
        "\n",
        "    except (json.JSONDecodeError, ValueError):\n",
        "        # Attempt 2: Regex-based correction\n",
        "        # We look for the list explicitly\n",
        "        match = re.search(r'\\[(.*?)\\]', clean_text, re.DOTALL)\n",
        "        if match:\n",
        "            extracted_content = f\"[{match.group(1)}]\"\n",
        "            try:\n",
        "                parsed_output_recovered = json.loads(extracted_content)\n",
        "                if isinstance(parsed_output_recovered, list):\n",
        "                    parsed_tags = parsed_output_recovered\n",
        "                    parsing_status = 'Recovered'\n",
        "            except (json.JSONDecodeError, ValueError):\n",
        "                pass\n",
        "\n",
        "    # --- F1 CALCULATION ---\n",
        "    parsed_tags = [str(tag) for tag in parsed_tags if tag is not None]\n",
        "    ground_truth_tags = [str(tag) for tag in ground_truth_tags if tag is not None]\n",
        "\n",
        "    all_unique_tags = sorted(list(set(parsed_tags + ground_truth_tags)))\n",
        "\n",
        "    if not all_unique_tags:\n",
        "        f1 = 1.0\n",
        "    elif not ground_truth_tags and parsed_tags:\n",
        "        f1 = 0.0\n",
        "    elif ground_truth_tags and not parsed_tags:\n",
        "        f1 = 0.0\n",
        "    else:\n",
        "        y_true = [1 if tag in ground_truth_tags else 0 for tag in all_unique_tags]\n",
        "        y_pred = [1 if tag in parsed_tags else 0 for tag in all_unique_tags]\n",
        "        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'parsing_status': parsing_status,\n",
        "        'parsed_tags': parsed_tags,\n",
        "        'f1_score': f1,\n",
        "    }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Infer and evaluate all answers"
      ],
      "metadata": {
        "id": "p6jZqmG4Ar-o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331f55f4",
        "outputId": "3538929f-f4d6-4021-ce65-a10633f4467f"
      },
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "print(f\"Loading Model with max_seq_length = {max_seq_length}...\")\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# --- 2. SIMPLE INFERENCE LOOP (No Chunks!) ---\n",
        "print(\"Starting Long-Context Inference...\")\n",
        "evaluation_results = []\n",
        "\n",
        "for example in tqdm(dataset_test_formatted, desc=\"Processing\"):\n",
        "    prompt = example['prompt']\n",
        "    ground_truth_tags = example['tags']\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate\n",
        "    # Since we have a massive context, we just feed the whole thing in.\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens = 256,\n",
        "            use_cache = True,\n",
        "            do_sample = False,\n",
        "            temperature = 0.0,\n",
        "             # Unsloth handles padding automatically usually, but being explicit is safe\n",
        "            pad_token_id = tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    # Slice off the input prompt\n",
        "    generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
        "    raw_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    # --- 3. STANDARD EVALUATION ---\n",
        "    # Clean JSON\n",
        "    if '}' in raw_output:\n",
        "        raw_output = raw_output[:raw_output.find('}') + 1]\n",
        "\n",
        "    # Evaluate\n",
        "    result = evaluate_response(raw_output, ground_truth_tags)\n",
        "\n",
        "    evaluation_results.append({\n",
        "        'original_prompt_len': inputs.input_ids.shape[1], # Log length to verify it worked\n",
        "        'ground_truth': ground_truth_tags,\n",
        "        'predicted': result['parsed_tags'],\n",
        "        'f1_score': result['f1_score'],\n",
        "        'raw_output': raw_output\n",
        "    })\n",
        "\n",
        "    # CRITICAL: Clear cache after massive context to avoid OOM on next iteration\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "print(f\"Done. Processed {len(evaluation_results)} documents.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Model with max_seq_length = 16384...\n",
            "Starting Long-Context Inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Processed 10 documents.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. REPORTING ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"INFERENCE REPORT: {len(evaluation_results)} documents\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if evaluation_results:\n",
        "    # 1. Calculate Global Metric\n",
        "    avg_f1 = sum(r['f1_score'] for r in evaluation_results) / len(evaluation_results)\n",
        "    print(f\"\\nGlobal Average F1 Score: {avg_f1:.4f}\")\n",
        "\n",
        "    # 2. Print Sample Table\n",
        "    print(\"\\n--- Sample Results (First 10) ---\")\n",
        "    print(f\"{'F1 Score':<10} | {'Ground Truth':<30} | {'Predicted':<30}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for res in evaluation_results[:10]:\n",
        "        # Truncate lists for cleaner printing\n",
        "        gt_str = str(res['ground_truth'])\n",
        "        pred_str = str(res['predicted'])\n",
        "        gt_display = (gt_str[:27] + '..') if len(gt_str) > 27 else gt_str\n",
        "        pred_display = (pred_str[:27] + '..') if len(pred_str) > 27 else pred_str\n",
        "\n",
        "        print(f\"{res['f1_score']:.4f}     | {gt_display:<30} | {pred_display:<30}\")\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "else:\n",
        "    print(\"No results generated.\")"
      ],
      "metadata": {
        "id": "FBxs_MwGBQz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1678375c-62b0-40d1-8e70-2aff843aaeab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "INFERENCE REPORT: 10 documents\n",
            "============================================================\n",
            "\n",
            "Global Average F1 Score: 0.4222\n",
            "\n",
            "--- Sample Results (First 10) ---\n",
            "F1 Score   | Ground Truth                   | Predicted                     \n",
            "--------------------------------------------------------------------------------\n",
            "1.0000     | []                             | []                            \n",
            "1.0000     | []                             | []                            \n",
            "1.0000     | []                             | []                            \n",
            "0.0000     | ['REFERENCE_ERROR']            | []                            \n",
            "0.1111     | ['REFERENCE_ERROR', 'EMOTIO..  | ['WHATABOUTISM', 'STRAWMAN'.. \n",
            "0.0000     | []                             | ['CHERRY_PICKING', 'EMOTION.. \n",
            "1.0000     | []                             | []                            \n",
            "0.1111     | ['REFERENCE_ERROR', 'EMOTIO..  | ['CHERRY_PICKING', 'STRAWMA.. \n",
            "0.0000     | []                             | ['WHATABOUTISM', 'CHERRY_PI.. \n",
            "0.0000     | []                             | ['CHERRY_PICKING', 'LEADING.. \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}