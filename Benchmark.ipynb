{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63a0f7ef003f4f1995845ef6b1459f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_520dc5d8be7e4688999ee3ff96093720",
              "IPY_MODEL_82632b07d9be4951ac3f02cda065fdfd",
              "IPY_MODEL_1706e1edcc624bbcb357da101bf91bfc"
            ],
            "layout": "IPY_MODEL_e1c793a0dc774dbb8987af2ab0f091ec"
          }
        },
        "520dc5d8be7e4688999ee3ff96093720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5c4da82ad1459fbf8ecf32e5329ef4",
            "placeholder": "​",
            "style": "IPY_MODEL_99d31d822abd444d8f8bde02a8889cee",
            "value": "Generating test split: "
          }
        },
        "82632b07d9be4951ac3f02cda065fdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7b89e35ba64642b98d61123b4b6c90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6a1f6c2411f4fb8b825f42391317ea5",
            "value": 1
          }
        },
        "1706e1edcc624bbcb357da101bf91bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d45d4bba211e469784daf6876a2a53b6",
            "placeholder": "​",
            "style": "IPY_MODEL_7b87bb83966b4580abed4f4d0bc3da39",
            "value": " 1521/0 [00:00&lt;00:00, 2760.61 examples/s]"
          }
        },
        "e1c793a0dc774dbb8987af2ab0f091ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5c4da82ad1459fbf8ecf32e5329ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d31d822abd444d8f8bde02a8889cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d7b89e35ba64642b98d61123b4b6c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c6a1f6c2411f4fb8b825f42391317ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d45d4bba211e469784daf6876a2a53b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b87bb83966b4580abed4f4d0bc3da39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49e53f771c4e40ed99e640abaa187104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d53358e48c824d6f895d9e64258e1e04",
              "IPY_MODEL_3a4f28e7f48d48bfbe0ddec8c1ca7d79",
              "IPY_MODEL_be3db9f798a340268b87b8b60003f428"
            ],
            "layout": "IPY_MODEL_39a1122a93bd4df79921d4a28e33a072"
          }
        },
        "d53358e48c824d6f895d9e64258e1e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b355a5731d48f29a9e7bf64ab6afae",
            "placeholder": "​",
            "style": "IPY_MODEL_81980137ca6e47a492fe212856321fe2",
            "value": "Map: 100%"
          }
        },
        "3a4f28e7f48d48bfbe0ddec8c1ca7d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_334fe1cbeb024df7bd025d792350fafb",
            "max": 1521,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96f31e31ec1546ff80e69ab8da1e9748",
            "value": 1521
          }
        },
        "be3db9f798a340268b87b8b60003f428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb917ddf912a4a69bbfdc8a2e9fea5dd",
            "placeholder": "​",
            "style": "IPY_MODEL_ddce79ec841346aaaea406fa8692858a",
            "value": " 1521/1521 [00:00&lt;00:00, 3525.97 examples/s]"
          }
        },
        "39a1122a93bd4df79921d4a28e33a072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b355a5731d48f29a9e7bf64ab6afae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81980137ca6e47a492fe212856321fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "334fe1cbeb024df7bd025d792350fafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f31e31ec1546ff80e69ab8da1e9748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb917ddf912a4a69bbfdc8a2e9fea5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddce79ec841346aaaea406fa8692858a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import libs"
      ],
      "metadata": {
        "id": "yp6KMqYL_LBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ],
      "metadata": {
        "id": "RQRC97HcyHnc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95be7d5b",
        "outputId": "4c951156-3970-41a5-87e4-760e157c69ba"
      },
      "source": [
        "!pip install --quiet vllm scikit-learn tqdm\n",
        "print(\"Required libraries unsloth, vllm, scikit-learn, and tqdm installed successfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.9/474.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.0/355.0 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m141.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.4/285.4 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m150.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.6/821.6 kB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth-zoo 2026.1.3 requires tyro, which is not installed.\n",
            "unsloth 2026.1.3 requires tyro, which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "unsloth-zoo 2026.1.3 requires torchao>=0.13.0, but you have torchao 0.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequired libraries unsloth, vllm, scikit-learn, and tqdm installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to drive for test dataset"
      ],
      "metadata": {
        "id": "dj7X1r7Y_Qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROgYyP62M3SW",
        "outputId": "959061eb-03c4-4930-b9a7-94a138133f48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and tokenizer"
      ],
      "metadata": {
        "id": "M47uCXWI_aen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = \"drive/MyDrive/mipd_test.jsonl\"\n",
        "MAX_NEW_TOKENS = 256\n",
        "max_seq_length = 16384\n",
        "base_model_dir = \"drive/MyDrive/bielik-4.5b-base\"\n",
        "TEST_ROWS = None # None for whole dataset\n",
        "lora_path = \"/content/drive/MyDrive/checkpoint-2686\" #None for base model"
      ],
      "metadata": {
        "id": "0_f3y0eLsiz5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from google.colab import userdata\n",
        "import torch\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = base_model_dir,\n",
        "    max_seq_length = max_seq_length, # Choose any for long context!\n",
        "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
        "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    # Removed lora_path from here\n",
        ")"
      ],
      "metadata": {
        "id": "XferaHy_ipFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the LoRA adapter separately\n",
        "if lora_path: # Check if lora_path is defined and not None\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        # Unsloth will infer these if not specified, or you can explicitly define them if needed\n",
        "        # for example: r=16, target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "        # lora_alpha=16, lora_dropout=0,\n",
        "        # bias=\"none\",\n",
        "        # use_gradient_checkpointing=\"unsloth\",\n",
        "        # random_state=3407,\n",
        "        # max_seq_length=max_seq_length,\n",
        "    )\n",
        "    model.load_adapter(lora_path, \"original_dataset_adapter\") # Added \"lora\" as the adapter_name"
      ],
      "metadata": {
        "id": "FtPlFInruX_p",
        "outputId": "51c607b7-fc40-4022-f30f-66ab01072ccd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.3: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.13.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and prepare dataset"
      ],
      "metadata": {
        "id": "N5OMhg3y_iaW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "63a0f7ef003f4f1995845ef6b1459f98",
            "520dc5d8be7e4688999ee3ff96093720",
            "82632b07d9be4951ac3f02cda065fdfd",
            "1706e1edcc624bbcb357da101bf91bfc",
            "e1c793a0dc774dbb8987af2ab0f091ec",
            "4a5c4da82ad1459fbf8ecf32e5329ef4",
            "99d31d822abd444d8f8bde02a8889cee",
            "7d7b89e35ba64642b98d61123b4b6c90",
            "c6a1f6c2411f4fb8b825f42391317ea5",
            "d45d4bba211e469784daf6876a2a53b6",
            "7b87bb83966b4580abed4f4d0bc3da39",
            "49e53f771c4e40ed99e640abaa187104",
            "d53358e48c824d6f895d9e64258e1e04",
            "3a4f28e7f48d48bfbe0ddec8c1ca7d79",
            "be3db9f798a340268b87b8b60003f428",
            "39a1122a93bd4df79921d4a28e33a072",
            "62b355a5731d48f29a9e7bf64ab6afae",
            "81980137ca6e47a492fe212856321fe2",
            "334fe1cbeb024df7bd025d792350fafb",
            "96f31e31ec1546ff80e69ab8da1e9748",
            "fb917ddf912a4a69bbfdc8a2e9fea5dd",
            "ddce79ec841346aaaea406fa8692858a"
          ]
        },
        "id": "014141ff",
        "outputId": "1c7ff815-20db-4b14-f98e-1b188f680fa4"
      },
      "source": [
        "import json\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 1. Load the test dataset\n",
        "dataset_test = load_dataset(\"json\", data_files={'test': test_data_path})\n",
        "\n",
        "# 3. Define a function named format_prompt\n",
        "def format_prompt(example):\n",
        "    # Combine instruction for system message and input for the user message\n",
        "    system_instruction = example['instruction']\n",
        "    user_message = example['input']\n",
        "\n",
        "    # Construct the ChatML formatted prompt\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_instruction},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "    example['prompt'] = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    # 5. Parse the output field into a Python list of strings (ground truth tags)\n",
        "    try:\n",
        "        # CLEANING STEP: Remove Markdown formatting\n",
        "        clean_json = example['output'].replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "        example['tags'] = json.loads(clean_json)['discovered_techniques']\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle cases where output might not be perfectly valid JSON (e.g., during training data prep)\n",
        "        example['tags'] = [] # Assign empty list if parsing fails\n",
        "        print(f\"Warning: Could not parse output: {example['output']}\")\n",
        "\n",
        "    # 6. Return the modified example\n",
        "    return example\n",
        "\n",
        "\n",
        "if(TEST_ROWS):\n",
        "  small_test_dataset = dataset_test['test'].select(range(TEST_ROWS))\n",
        "else:\n",
        "  small_test_dataset = dataset_test['test']\n",
        "# 7. Apply the format_prompt function to the loaded test dataset\n",
        "original_columns = small_test_dataset.column_names\n",
        "dataset_test_formatted = small_test_dataset.map(format_prompt, remove_columns=original_columns)\n",
        "\n",
        "print(\"Formatted prompts and ground truth tags generated for the test dataset.\")\n",
        "print(dataset_test_formatted)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63a0f7ef003f4f1995845ef6b1459f98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1521 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49e53f771c4e40ed99e640abaa187104"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted prompts and ground truth tags generated for the test dataset.\n",
            "Dataset({\n",
            "    features: ['prompt', 'tags'],\n",
            "    num_rows: 1521\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define evaluation function\n",
        "Metric 1: Parsing Success Rate (Did it output valid JSON?).\n",
        "\n",
        "Metric 2: Format Correction Rate (How many invalid jsons were recovered?)\n",
        "\n",
        "Metric 3: Classification Performance (If parsable, how accurate?).\n"
      ],
      "metadata": {
        "id": "5NAGs3A6AJ9C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c58a713"
      },
      "source": [
        "import json\n",
        "import re\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_response(response_text: str, ground_truth_tags: list):\n",
        "    \"\"\"\n",
        "    Evaluates response with support for Dict format {\"discovered_techniques\": []}\n",
        "    and Markdown stripping.\n",
        "    \"\"\"\n",
        "    parsed_tags = []\n",
        "    parsing_status = 'Failed'\n",
        "\n",
        "    # 0. Pre-processing: Strip Markdown (Crucial for Strict Success)\n",
        "    # If we don't do this, valid JSON wrapped in ```json will fail strict parsing\n",
        "    clean_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "    # Attempt 1: Strict JSON parsing\n",
        "    try:\n",
        "        parsed_output = json.loads(clean_text)\n",
        "\n",
        "        # CASE A: Output is the expected Dictionary\n",
        "        if isinstance(parsed_output, dict):\n",
        "            # Extract the specific key we trained on\n",
        "            parsed_tags = parsed_output.get(\"discovered_techniques\", [])\n",
        "            # Check if the inner content is actually a list\n",
        "            if not isinstance(parsed_tags, list):\n",
        "                 # Try to force it if it's a string representation\n",
        "                 parsed_tags = []\n",
        "            parsing_status = 'Strict Success'\n",
        "\n",
        "        # CASE B: Model outputted a raw List (unlikely but possible)\n",
        "        elif isinstance(parsed_output, list):\n",
        "            parsed_tags = parsed_output\n",
        "            parsing_status = 'Strict Success'\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Parsed output is not a Dict or List.\")\n",
        "\n",
        "    except (json.JSONDecodeError, ValueError):\n",
        "        # Attempt 2: Regex-based correction\n",
        "        # We look for the list explicitly\n",
        "        match = re.search(r'\\[(.*?)\\]', clean_text, re.DOTALL)\n",
        "        if match:\n",
        "            extracted_content = f\"[{match.group(1)}]\"\n",
        "            try:\n",
        "                parsed_output_recovered = json.loads(extracted_content)\n",
        "                if isinstance(parsed_output_recovered, list):\n",
        "                    parsed_tags = parsed_output_recovered\n",
        "                    parsing_status = 'Recovered'\n",
        "            except (json.JSONDecodeError, ValueError):\n",
        "                pass\n",
        "\n",
        "    # --- F1 CALCULATION ---\n",
        "    parsed_tags = [str(tag) for tag in parsed_tags if tag is not None]\n",
        "    ground_truth_tags = [str(tag) for tag in ground_truth_tags if tag is not None]\n",
        "\n",
        "    all_unique_tags = sorted(list(set(parsed_tags + ground_truth_tags)))\n",
        "\n",
        "    if not all_unique_tags:\n",
        "        f1 = 1.0\n",
        "    elif not ground_truth_tags and parsed_tags:\n",
        "        f1 = 0.0\n",
        "    elif ground_truth_tags and not parsed_tags:\n",
        "        f1 = 0.0\n",
        "    else:\n",
        "        y_true = [1 if tag in ground_truth_tags else 0 for tag in all_unique_tags]\n",
        "        y_pred = [1 if tag in parsed_tags else 0 for tag in all_unique_tags]\n",
        "        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'parsing_status': parsing_status,\n",
        "        'parsed_tags': parsed_tags,\n",
        "        'f1_score': f1,\n",
        "    }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Infer and evaluate all answers"
      ],
      "metadata": {
        "id": "p6jZqmG4Ar-o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331f55f4",
        "outputId": "499ade41-e072-40f1-f2c7-d16f3e2cbc72"
      },
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "print(f\"Loading Model with max_seq_length = {max_seq_length}...\")\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# --- 2. SIMPLE INFERENCE LOOP (No Chunks!) ---\n",
        "print(\"Starting Long-Context Inference...\")\n",
        "evaluation_results = []\n",
        "\n",
        "for example in tqdm(dataset_test_formatted, desc=\"Processing\"):\n",
        "    prompt = example['prompt']\n",
        "    ground_truth_tags = example['tags']\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate\n",
        "    # Since we have a massive context, we just feed the whole thing in.\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens = 256,\n",
        "            use_cache = True,\n",
        "            do_sample = False,\n",
        "            temperature = 0.0,\n",
        "             # Unsloth handles padding automatically usually, but being explicit is safe\n",
        "            pad_token_id = tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    # Slice off the input prompt\n",
        "    generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
        "    raw_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    # --- 3. STANDARD EVALUATION ---\n",
        "    # Clean JSON\n",
        "    if '}' in raw_output:\n",
        "        raw_output = raw_output[:raw_output.find('}') + 1]\n",
        "\n",
        "    # Evaluate\n",
        "    result = evaluate_response(raw_output, ground_truth_tags)\n",
        "\n",
        "    evaluation_results.append({\n",
        "        'original_prompt_len': inputs.input_ids.shape[1], # Log length to verify it worked\n",
        "        'ground_truth': ground_truth_tags,\n",
        "        'predicted': result['parsed_tags'],\n",
        "        'f1_score': result['f1_score'],\n",
        "        'raw_output': raw_output\n",
        "    })\n",
        "\n",
        "    # CRITICAL: Clear cache after massive context to avoid OOM on next iteration\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "print(f\"Done. Processed {len(evaluation_results)} documents.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Model with max_seq_length = 16384...\n",
            "Starting Long-Context Inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:  43%|████▎     | 661/1521 [1:13:53<3:16:59, 13.74s/it]Unsloth: Input IDs of shape torch.Size([1, 18832]) with length 18832 > the model's max sequence length of 16384.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            "Processing:  61%|██████▏   | 934/1521 [1:45:24<1:32:11,  9.42s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. REPORTING ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"INFERENCE REPORT: {len(evaluation_results)} documents\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if evaluation_results:\n",
        "    # 1. Calculate Global Metric\n",
        "    avg_f1 = sum(r['f1_score'] for r in evaluation_results) / len(evaluation_results)\n",
        "    print(f\"\\nGlobal Average F1 Score: {avg_f1:.4f}\")\n",
        "\n",
        "    # 2. Print Sample Table\n",
        "    print(\"\\n--- Sample Results (First 10) ---\")\n",
        "    print(f\"{'F1 Score':<10} | {'Ground Truth':<30} | {'Predicted':<30}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for res in evaluation_results[:10]:\n",
        "        # Truncate lists for cleaner printing\n",
        "        gt_str = str(res['ground_truth'])\n",
        "        pred_str = str(res['predicted'])\n",
        "        gt_display = (gt_str[:27] + '..') if len(gt_str) > 27 else gt_str\n",
        "        pred_display = (pred_str[:27] + '..') if len(pred_str) > 27 else pred_str\n",
        "\n",
        "        print(f\"{res['f1_score']:.4f}     | {gt_display:<30} | {pred_display:<30}\")\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "else:\n",
        "    print(\"No results generated.\")"
      ],
      "metadata": {
        "id": "FBxs_MwGBQz7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}